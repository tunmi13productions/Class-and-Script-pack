{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tunmi13productions/Class-and-Script-pack/blob/main/Hina_Modified_Realtime_Voice_Changer_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### w-okada's Voice Changer | **Google Colab** / **Kaggle**\n",
        "\n",
        "---\n",
        "\n",
        "##**READ ME - VERY IMPORTANT**\n",
        "\n",
        "This is an attempt to run [Realtime Voice Changer](https://github.com/w-okada/voice-changer) on Google Colab and Kaggle, still not perfect but is totally usable, you can use the following settings for better results:\n",
        "\n",
        "If you're using a index: `f0: RMVPE_ONNX | Chunk: 112 or higher | Extra: 8192`\\\n",
        "If you're not using a index: `f0: RMVPE_ONNX | Chunk: 96 or higher | Extra: 16384`\\\n",
        "**Don't forget to select your GPU in the GPU field (<b>Tesla T4</b>, for free users on Colab | P100 on Kaggle)*\n",
        "> Seems that PTH models performance better than ONNX for now, you can still try ONNX models and see if it satisfies you\n",
        "\n",
        "\n",
        "*You can always [click here](https://rentry.co/VoiceChangerGuide#gpu-chart-for-known-working-chunkextra) to check if these settings are up-to-date*\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "\n",
        "###Always use GPU (**VERY VERY VERY IMPORTANT!**)\n",
        "You need to use a GPU so the Voice Changer can work faster and better\\\n",
        "Use the menu above and click on **Runtime** » **Change runtime** » **Hardware acceleration** to select a GPU (**T4 is the free one**)\n",
        "\n",
        "---\n",
        "\n",
        "# **Credits and Support**\n",
        "Realtime Voice Changer by [w-okada](https://github.com/w-okada)\\\n",
        "Colab files updated by [rafacasari](https://github.com/Rafacasari)\\\n",
        "Recommended settings by [Blanc](https://github.com/Blanc-dot)\\\n",
        "Modified again by [Hina](https://github.com/HinaBl)\\\n",
        "Enable FCPE by [TheTrustedComputer](https://github.com/TheTrustedComputer)\\\n",
        "Addition of HRZN [Nick088](https://github.com/Nick088Official)\n",
        "\n",
        "Need help? [AI Hub Discord](https://discord.gg/aihub) » ***#help-realtime-vc***\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oup1gy4hi7nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=================Updated=================\n",
        "# @title **[1]** Clone repository and install dependencies\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.**\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import threading\n",
        "import shutil\n",
        "import base64\n",
        "import codecs\n",
        "\n",
        "# Configs\n",
        "Run_Cell=0\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "# @title **[Optional]** Connect to Google Drive\n",
        "# @markdown Using Google Drive will automatically save your uploaded models for later use.\n",
        "\n",
        "Use_Drive=True #@param {type:\"boolean\"}\n",
        "notebook_env=0\n",
        "# Check what platform the notebook is running on\n",
        "if os.path.exists('/content'):\n",
        "  notebook_env=1\n",
        "  print(\"Welcome to ColabMod\")\n",
        "  from google.colab import drive\n",
        "\n",
        "elif os.path.exists('/kaggle/working'):\n",
        "  notebook_env=2\n",
        "  print(\"Welcome to Kaggle Mod\")\n",
        "else:\n",
        "  notebook_env=3\n",
        "  print(\"Welcome!\")\n",
        "\n",
        "\n",
        "\n",
        "externalgit=codecs.decode('uggcf://tvguho.pbz/j-bxnqn/ibvpr-punatre.tvg','rot_13')\n",
        "rvctimer=codecs.decode('uggcf://tvguho.pbz/uvanoy/eipgvzre.tvg','rot_13')\n",
        "pathloc=codecs.decode('ibvpr-punatre','rot_13')\n",
        "\n",
        "from IPython.display import clear_output, Javascript\n",
        "\n",
        "def update_timer_and_print():\n",
        "    global timer\n",
        "    while True:\n",
        "        hours, remainder = divmod(timer, 3600)\n",
        "        minutes, seconds = divmod(remainder, 60)\n",
        "        timer_str = f'{hours:02}:{minutes:02}:{seconds:02}'\n",
        "        print(f'\\rTimer: {timer_str}', end='', flush=True)  # Print without a newline\n",
        "        time.sleep(1)\n",
        "        timer += 1\n",
        "timer = 0\n",
        "threading.Thread(target=update_timer_and_print, daemon=True).start()\n",
        "\n",
        "!pip install colorama --quiet\n",
        "from colorama import Fore, Style\n",
        "\n",
        "print(f\"{Fore.CYAN}> Cloning the repository...{Style.RESET_ALL}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!git clone --depth 1 $externalgit &> /dev/null\n",
        "%cd $pathloc\n",
        "\n",
        "# !git fetch --depth 1 origin 11672e965338c852aac6e17b0f724d86db07b7bb\n",
        "# !git reset --hard 11672e965338c852aac6e17b0f724d86db07b7bb\n",
        "# !git clean -df\n",
        "%cd ../\n",
        "\n",
        "\n",
        "if notebook_env==1:\n",
        "  if Use_Drive==True:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "      drive.mount('/content/drive')\n",
        "\n",
        "      !mkdir -p /content/drive/MyDrive/voice-changer/server/model_dir\n",
        "      !rm -rf /content/voice-changer/server/model_dir\n",
        "\n",
        "      drive_dir = \"/content/drive/MyDrive/voice-changer/server/model_dir\"\n",
        "      colab_dir = \"/content/voice-changer/server/model_dir\"\n",
        "      time.sleep(5)\n",
        "\n",
        "      os.symlink(drive_dir,colab_dir,True)\n",
        "    # %cd /content/drive/MyDrive\n",
        "print(f\"{Fore.GREEN}> Successfully cloned the repository!{Style.RESET_ALL}\")\n",
        "%cd $pathloc/server/\n",
        "\n",
        "\n",
        "#custom sub\n",
        "if notebook_env==1:\n",
        "  !sed -i \"s/-.-.-.-/Colab.Mod/\" '../client/demo/dist/assets/gui_settings/version.txt'\n",
        "elif notebook_env==2:\n",
        "  !sed -i \"s/-.-.-.-/Kaggle.Mod/\" '../client/demo/dist/assets/gui_settings/version.txt'\n",
        "elif notebook_env==3:\n",
        "  !sed -i \"s/-.-.-.-/Online.Mod/\" '../client/demo/dist/assets/gui_settings/version.txt'\n",
        "else:\n",
        "  !sed -i \"s/-.-.-.-/Online.Mod/\" '../client/demo/dist/assets/gui_settings/version.txt'\n",
        "  print(\"Notebook Env Not Found\")\n",
        "\n",
        "\n",
        "print(f\"{Fore.CYAN}> Installing libportaudio2...{Style.RESET_ALL}\")\n",
        "!apt-get -y install -qq libportaudio2 > /dev/null 2>&1\n",
        "!npm install -g @hrzn/cli > /dev/null 2>&1\n",
        "!sudo apt-get -qq update > /dev/null 2>&1\n",
        "!sudo apt-get install -qq portaudio19-dev -y > /dev/null 2>&1\n",
        "!apt install -qq psmisc > /dev/null 2>&1\n",
        "\n",
        "!sed -i '/torch==/d' requirements.txt\n",
        "\n",
        "!sed -i '/torchaudio==/d' requirements.txt\n",
        "\n",
        "!sed -i '/numpy==/d' requirements.txt\n",
        "\n",
        "# Enabled FCPE\n",
        "# !sed -i '/from voice_changer.RVC.pitchExtractor.RMVPEPitchExtractor import RMVPEPitchExtractor/a\\from voice_changer.RVC.pitchExtractor.FcpePitchExtractor import FcpePitchExtractor' voice_changer/RVC/pitchExtractor/PitchExtractorManager.py\n",
        "\n",
        "print(f\"{Fore.CYAN}> Installing pre-dependencies...{Style.RESET_ALL}\")\n",
        "# Install dependencies that are missing from requirements.txt and pyngrok\n",
        "!pip install pip==23.3.1 --quiet\n",
        "!pip install faiss-gpu --quiet\n",
        "!pip install fairseq --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install pyworld --no-build-isolation --quiet\n",
        "# Install webstuff\n",
        "import asyncio\n",
        "import re\n",
        "!pip install gdown portpicker torchfcpe\n",
        "print(f\"{Fore.CYAN}> Installing dependencies from requirements.txt...{Style.RESET_ALL}\")\n",
        "!pip install -r requirements.txt --quiet\n",
        "clear_output()\n",
        "Run_Cell=1\n",
        "print(f\"{Fore.GREEN}> Successfully installed all packages!{Style.RESET_ALL}\")"
      ],
      "metadata": {
        "id": "86wTFmqsNMnD",
        "cellView": "form"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **[Optional]** Upload a voice model (Run this before running the Voice Changer)\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "\n",
        "model_slot = 0 # @param {type:\"number\"}\n",
        "model_slot = str(model_slot)\n",
        "\n",
        "!rm -rf model_dir/$model_slot\n",
        "#@markdown **[Optional]** Add an icon to the model\n",
        "icon_link = \"https://i.scdn.co/image/ab6761610000e5ebbab6de14398281b2d37bc0b5\" #@param {type:\"string\"}\n",
        "icon_link = '\"'+icon_link+'\"'\n",
        "!mkdir model_dir\n",
        "!mkdir model_dir/$model_slot\n",
        "#@markdown Put your model's download link here `(must be a zip file)` only supports **huggingface.co** & **google drive**<br>\n",
        "model_link = \"https://drive.google.com/open?id=1-4mjsmdV4hToQMDGt_9c6CfSMoQ7dnl9&usp=drive_fs\"  #@param {type:\"string\"}\n",
        "\n",
        "if model_link.startswith(\"https://www.weights.gg\") or model_link.startswith(\"https://weights.gg\"):\n",
        "  print(\"Links from weights.gg is no longer supported.\")\n",
        "  sys.exit()\n",
        "elif model_link.startswith(\"https://drive.google.com\"):\n",
        "  model_link = '\"'+model_link+'\"'\n",
        "  !gdown $model_link --fuzzy -O model.zip\n",
        "  print(\"Model from Drive\")\n",
        "elif model_link.startswith(\"https://huggingface.co\"):\n",
        "  model_link = model_link\n",
        "  model_link = '\"'+model_link+'\"'\n",
        "  !curl -L $model_link > model.zip\n",
        "  print(\"Model from hugginface Link\")\n",
        "else:\n",
        "  model_link = model_link\n",
        "  model_link = '\"'+model_link+'\"'\n",
        "  !curl -L -O $model_link\n",
        "  !mv ./*.pth model_dir/$model_slot/\n",
        "  print('Model(.pth) or a direct model link.')\n",
        "\n",
        "# Conditionally set the iconFile based on whether icon_link is empty\n",
        "if icon_link == '\"\"':\n",
        "    iconFile = \"\"\n",
        "    print(\"icon_link is empty, so no icon file will be downloaded.\")\n",
        "else:\n",
        "    iconFile = \"icon.png\"\n",
        "    !curl -L $icon_link > model_dir/$model_slot/icon.png\n",
        "\n",
        "\n",
        "!unzip model.zip -d model_dir/$model_slot\n",
        "\n",
        "!mv model_dir/$model_slot/*/* model_dir/$model_slot/\n",
        "!rm -rf model_dir/$model_slot/*/\n",
        "!rm -rf model.zip\n",
        "#@markdown **Model Voice Convertion Setting**\n",
        "Tune = 12 #@param {type:\"slider\",min:-50,max:50,step:1}\n",
        "Index = 0 #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "\n",
        "param_link = \"\"\n",
        "if param_link == \"\":\n",
        "  paramset = requests.get(\"https://pastebin.com/raw/SAKwUCt1\").text\n",
        "  exec(paramset)\n",
        "\n",
        "clear_output()\n",
        "print(\"\\033[93mModel with the name of \"+model_name+\" has been Imported to slot \"+model_slot)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Arp4kTo8kSna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import subprocess, threading, time, socket, urllib.request, portpicker\n",
        "from IPython.display import clear_output, Javascript\n",
        "from IPython.display import Audio, display\n",
        "PORT = portpicker.pick_unused_port()\n",
        "#=======================Updated=========================\n",
        "\n",
        "# @title Start Server using **NGROK** or **HRZN**\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (~1-2 minutes)\n",
        "\n",
        "#======================Tunnels===========================\n",
        "\n",
        "TUNNEL = \"HRZN\" #@param [\"NGROK\",\"HRZN\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown You'll need a ngrok or hrzn account, but <font color=green>**it's free**</font> and easy to create!\n",
        "# @markdown ---\n",
        "# @markdown **1** - Create a <font color=green>**free**</font> account at [ngrok](https://dashboard.ngrok.com/signup) / [hrzn](https://hrzn.run/login) or **login with Google/Github account**\\\n",
        "# @markdown **2** - If you didn't logged in with Google/Github, you will need to **verify your e-mail**!\\\n",
        "# @markdown **3** - Get your [ngrok](https://dashboard.ngrok.com/get-started/your-authtoken) or [hrzn](https://hrzn.run/dashboard) to get your auth token, and place it here:\n",
        "Token = '2rPgHgr09i1m7arqHjYWVuFE3Y7_81e4hAB36jXPG33HgzqoF' # @param {type:\"string\"}\n",
        "# @markdown **4** - *(optional for ngrok)* Change to a region near to you or keep at United States if increase latency\\\n",
        "# @markdown `Default Region: ap - Asia/Pacific (Singapore)`\n",
        "Region = \"us - United States (Ohio)\" # @param [\"ap - Asia/Pacific (Singapore)\", \"au - Australia (Sydney)\",\"eu - Europe (Frankfurt)\", \"in - India (Mumbai)\",\"jp - Japan (Tokyo)\",\"sa - South America (Sao Paulo)\", \"us - United States (Ohio)\"]\n",
        "\n",
        "#@markdown **5** - *(optional)* Other options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "Play_Notification = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# ---------------------------------\n",
        "# DO NOT TOUCH ANYTHING DOWN BELOW!\n",
        "# ---------------------------------\n",
        "\n",
        "# Check if Run_Cell\n",
        "if 'Run_Cell' not in globals():\n",
        "    print(\"No, Go back to the first cell and run it\")\n",
        "else:\n",
        "  if Run_Cell == 0:\n",
        "    print(\"No, Go back to the first cell and run it\")\n",
        "  else:\n",
        "    if TUNNEL == \"NGROK\":\n",
        "      from pyngrok import conf, ngrok\n",
        "      MyConfig = conf.PyngrokConfig()\n",
        "      MyConfig.auth_token = Token\n",
        "      MyConfig.region = Region[0:2]\n",
        "      #conf.get_default().authtoken = Token\n",
        "      #conf.get_default().region = Region\n",
        "      conf.set_default(MyConfig);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      ngrokConnection = ngrok.connect(PORT)\n",
        "      public_url = ngrokConnection.public_url\n",
        "    elif TUNNEL == \"HRZN\":\n",
        "      !rm -rf url.txt\n",
        "      !hrzn login $Token\n",
        "      os.system(f\"hrzn tunnel http://localhost:{PORT} >> url.txt 2>&1 &\")\n",
        "      time.sleep(5)\n",
        "\n",
        "      with open('url.txt', 'r') as file:\n",
        "        public_url = file.read()\n",
        "        public_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url.txt\n",
        "        public_url = public_url[0]\n",
        "\n",
        "\n",
        "    def play_notification_sound():\n",
        "        display(Audio(url='https://raw.githubusercontent.com/hinabl/rmvpe-ai-kaggle/main/custom/audios/notif.mp3', autoplay=True))\n",
        "\n",
        "\n",
        "    def wait_for_server():\n",
        "        while True:\n",
        "            time.sleep(0.5)\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "            if result == 0:\n",
        "                break\n",
        "            sock.close()\n",
        "        if ClearConsole:\n",
        "            clear_output()\n",
        "        print(\"--------- SERVER READY! ---------\")\n",
        "        print(\"Your server is available at:\")\n",
        "        print(public_url)\n",
        "        print(\"---------------------------------\")\n",
        "        if Play_Notification==True:\n",
        "          play_notification_sound()\n",
        "\n",
        "    threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "\n",
        "    mainpy=codecs.decode('ZZIPFreireFVB.cl','rot_13')\n",
        "    mainname=codecs.decode('ZZIPFreireFVB','rot_13')\n",
        "    !mv {mainpy} HVoice.py\n",
        "    !sed -i \"s/MMVCServerSIO/HVoice/\" HVoice.py\n",
        "    !python3 HVoice.py \\\n",
        "      -p {PORT} \\\n",
        "      --https False \\\n",
        "      --content_vec_500 pretrain/checkpoint_best_legacy_500.pt \\\n",
        "      --content_vec_500_onnx pretrain/content_vec_500.onnx \\\n",
        "      --content_vec_500_onnx_on false \\\n",
        "      --hubert_base pretrain/hubert_base.pt \\\n",
        "      --hubert_base_jp pretrain/rinna_hubert_base_jp.pt \\\n",
        "      --hubert_soft pretrain/hubert/hubert-soft-0d54a1f4.pt \\\n",
        "      --nsf_hifigan pretrain/nsf_hifigan/model \\\n",
        "      --crepe_onnx_full pretrain/crepe_onnx_full.onnx \\\n",
        "      --crepe_onnx_tiny pretrain/crepe_onnx_tiny.onnx \\\n",
        "      --rmvpe pretrain/rmvpe.pt \\\n",
        "      --model_dir model_dir \\\n",
        "      --samples samples.json \\\n",
        "      --allowed-origins {public_url}\n",
        "\n",
        "    if TUNNEL == \"NGROK\":\n",
        "      ngrok.disconnect(ngrokConnection.public_url)\n",
        "      print(\"--------- SERVER STOPPED! ---------\")\n",
        "    elif TUNNEL == \"HRZN\":\n",
        "      !rm -rf url.txt\n",
        "      !fuser -k ${PORT}\n",
        "      print(\"--------- SERVER STOPPED! ---------\")"
      ],
      "metadata": {
        "id": "lLWQuUd7WW9U",
        "cellView": "form"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.pinimg.com/474x/de/72/9e/de729ecfa41b69901c42c82fff752414.jpg)\n",
        "![](https://i.pinimg.com/474x/de/72/9e/de729ecfa41b69901c42c82fff752414.jpg)"
      ],
      "metadata": {
        "id": "i8od_nC6kh1r"
      }
    }
  ]
}